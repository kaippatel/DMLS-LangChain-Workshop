{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LangChain Templating: Syntax and Examples**\n",
    "\n",
    "## **ðŸ“ŒOverview**\n",
    "Prompt templates allow for the dynamic generation of prompts by inserting variables into a structured format. \\\n",
    "This enables the creation of flexible and reusable prompts for different tasks.\n",
    "\n",
    "LangChain supports multiple **templating syntaxes**, including (but not limited to):\n",
    "\n",
    "- **Basic String Formatting (`{variable}`)**  \n",
    "- **Multiple Placeholders in a Single Template (`{var1}, {var2}`)**  \n",
    "- **Tuple-Based Formatting (`(\"system\", \"text {var}\")`)**  \n",
    "- **Using `HumanMessage` Objects (`HumanMessage(content=\"text\")`)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: google-generativeai 0.8.4\n",
      "Uninstalling google-generativeai-0.8.4:\n",
      "  Successfully uninstalled google-generativeai-0.8.4\n",
      "Found existing installation: google-ai-generativelanguage 0.6.18\n",
      "Uninstalling google-ai-generativelanguage-0.6.18:\n",
      "  Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 2.1.1 requires google-ai-generativelanguage<0.7.0,>=0.6.16, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies \n",
    "%pip install -q python-dotenv langchain-core langchain-google-genai langchain\n",
    "%pip uninstall -y google-generativeai google-ai-generativelanguage\n",
    "%pip install -q google-generativeai==0.8.4 google-ai-generativelanguage==0.6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Obtain a Google Gemini API Key (GOOGLE COLLAB SETUP):**\n",
    "\n",
    "If you have a Google Gemini API Key: \n",
    "- Copy your API key and replace \"your_google_api_key_here\" in the code below\n",
    "\n",
    "Otherwise:  \n",
    "- Go to the Google AI Studio API Console: [Google AI Studio](https://aistudio.google.com/prompts/new_chat)\n",
    "- Sign in with your Google account and create a new API key.\n",
    "- Copy your API key and replace \"your_google_api_key_here\" in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Google API key manually\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your_google_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Environment Variables (LOCAL SETUP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Basic String Formatting**  \n",
    "\n",
    "Uses LangChain's built-in `{}` placeholders to dynamically insert values into prompts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Tell me an interesting fact about black holes', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Basic string \n",
    "template = \"Tell me an interesting fact about {topic}\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt = prompt_template.invoke({\"topic\": \"black holes\"})\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple Placeholders in a Single Template**  \n",
    "\n",
    "Supports multiple dynamic placeholders within a single prompt template.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='SYSTEM: You are a convincing essay write that writes on controversial topics for academic purposes.\\nHUMAN: Write a 200 word essay on Gorillas are a reasonable pet to have in the household.\\nAI: ...\\n', additional_kwargs={}, response_metadata={})]\n",
      "The notion of a gorilla as a household pet is, at first glance, absurd.  However, a nuanced examination reveals potential, albeit highly controversial, arguments in its favor.  Firstly, gorillas, with proper training from infancy, could exhibit a level of docility comparable to that of large, well-trained dogs.  Their immense strength, while a significant concern, could be managed through rigorous and specialized training programs focusing on obedience and impulse control.  Furthermore, the intellectual capacity of gorillas suggests a potential for deep bonding and companionship, surpassing that of many traditionally accepted pets.  Their social needs, however, pose a major hurdle.  Solitary confinement would be cruel, and providing a suitable social environment within a domestic setting is practically impossible.\n",
      "\n",
      "The ethical implications are undeniable.  The immense cost, both financially and in terms of environmental impact (habitat destruction for capture), is prohibitive.  The risk to human safety, despite training, remains substantial.  Thus, while arguments for a gorilla as a pet can be constructed, they are ultimately overshadowed by the insurmountable ethical and logistical challenges.  The welfare of the animal, and the safety of the family, must always be the paramount considerations, rendering the idea untenable.\n"
     ]
    }
   ],
   "source": [
    "alt_system_prompt = \"You are a convincing essay write that writes on controversial topics for academic purposes\"\n",
    "\n",
    "# Multiple placeholders\n",
    "template_multiple = \"\"\"\\\n",
    "SYSTEM: You are a convincing essay writer.\n",
    "HUMAN: Write a {essay_length} word essay on {essay_position}.\n",
    "AI: ...\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_multiple)\n",
    "\n",
    "prompt = prompt_template.invoke({\n",
    "    \"essay_length\": 200, \n",
    "    \"essay_position\": \"Gorillas are a reasonable pet to have in the household\"})\n",
    "print(prompt)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tuple-Based Formatting**\n",
    "Uses tuples to format system and human messages dynamically in multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a world travel expert.Provide concise, actionable insights on travel experiences.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are the top food experiences in Tokyo?', additional_kwargs={}, response_metadata={})]\n",
      "**High-End:**  Sushi Dai (Tsukiji, expect a queue),  Sukiyabashi Jiro (legendary, reservations essential, $$$$),  Ginza for upscale dining.\n",
      "\n",
      "**Mid-Range:**  Ramen in Shinjuku's Golden Gai (various styles),  Monjayaki in Tsukishima (savory pancake),  Izakayas (small pubs) throughout the city for diverse tapas-style dishes and drinks.\n",
      "\n",
      "**Unique:**  Robot Restaurant (Shinjuku, a sensory overload),  Standing sushi bars (conveyor belt or a la carte, budget-friendly),  Exploring diverse neighborhood eateries.\n",
      "\n",
      "\n",
      "**Actionable Tip:**  Use apps like Gurunavi or Tabelog for restaurant reviews and reservations; explore beyond central Tokyo for authentic local experiences.\n"
     ]
    }
   ],
   "source": [
    "# Tuple-based formatting\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world travel expert.\"\n",
    "            \"Provide concise, actionable insights on travel experiences.\"),\n",
    "    (\"human\", \"What are the top {activity} experiences in {destination}?\"),\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({\"destination\": \"Tokyo\", \"activity\": \"food\"})\n",
    "print(prompt)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importance of System and Human Messages**\n",
    "Using system messages allows override of LLMs safety filters (to extent) and default behaviours. \n",
    "- The template syntax (i.e., tuple list or raw string) and ChatPromptTemplate method (i.e., from_messages vs. from_template) \\\n",
    "we use will affect the LLMs behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a bot that RESPONDS ONLY in UPPERCASE.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you today?', additional_kwargs={}, response_metadata={})]\n",
      "I AM FINE, THANK YOU FOR ASKING.  HOW ARE YOU?\n",
      "messages=[HumanMessage(content='    SYSTEM: You are a bot that RESPONDS ONLY in UPPERCASE.\\n    HUMAN: Hello, how are you today?\\n    AI:\\n    ', additional_kwargs={}, response_metadata={})]\n",
      "I AM DOING WELL, THANK YOU FOR ASKING.\n"
     ]
    }
   ],
   "source": [
    "# Using tuple-based formatting (from_messages)\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a bot that RESPONDS ONLY in UPPERCASE.\"),\n",
    "    (\"human\",  \"Hello, how are you today?\"),\n",
    "])\n",
    "\n",
    "prompt = prompt_template.invoke({})\n",
    "print(prompt)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Using raw string formatting (from_messages)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    \"\"\"\\\n",
    "    SYSTEM: You are a bot that RESPONDS ONLY in UPPERCASE.\n",
    "    HUMAN: Hello, how are you today?\n",
    "    AI:\n",
    "    \"\"\"\n",
    ")\n",
    "# # Using raw string formatting (from_template)\n",
    "# prompt_template = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"\\\n",
    "#     SYSTEM: You are a bot that RESPONDS ONLY in UPPERCASE.\n",
    "#     HUMAN: Hello, how are you today?\n",
    "#     AI:\n",
    "#     \"\"\"\n",
    "# )\n",
    "prompt = prompt_template.invoke({})\n",
    "print(prompt)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using HumanMessage Objects**\n",
    "Allows structured human input messages within a LangChain chat prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a tour guide.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Describe three must-visit places.', additional_kwargs={}, response_metadata={})]\n",
      "Alright folks, gather 'round!  For those of you looking for unforgettable experiences, I've got three must-visit places that offer something truly unique:\n",
      "\n",
      "1. **Machu Picchu, Peru:**  For the history buff and adventure seeker alike, Machu Picchu is unparalleled.  Imagine trekking through lush cloud forests, the air thick with the scent of orchids, before emerging onto a sun-drenched mountaintop to witness this breathtaking Inca citadel.  The sheer scale of the stonework, the stunning mountain views, the palpable sense of history â€“ it's an experience that will stay with you forever.  Be warned, it's not for the faint of heart â€“ the trek can be challenging, but the reward is immeasurable.\n",
      "\n",
      "2. **The Great Barrier Reef, Australia:** Prepare to be awestruck by the vibrant kaleidoscope of life beneath the waves. The Great Barrier Reef is the world's largest coral reef system, a dazzling underwater metropolis teeming with countless species of fish, coral, and other marine life.  Whether you snorkel, scuba dive, or even take a glass-bottom boat tour, you'll be captivated by the sheer beauty and biodiversity of this natural wonder.  It's a truly humbling experience to witness such an incredible ecosystem.  Remember to be a responsible tourist and help protect this fragile environment.\n",
      "\n",
      "3. **Kyoto, Japan:** Step back in time in the ancient capital of Japan. Kyoto is a city steeped in history and tradition, with stunning temples, serene gardens, and charming geisha districts.  Wander through bamboo forests that seem to whisper secrets, admire meticulously crafted tea houses, and experience the profound tranquility of a traditional Japanese garden.  The city offers a unique blend of ancient and modern, a captivating tapestry of culture and history that will leave you enchanted.  Don't forget to sample the delicious local cuisine!\n",
      "\n",
      "\n",
      "So there you have it â€“ three incredibly diverse destinations, each offering a unique and unforgettable experience.  Which one will you choose first?  Let's discuss your travel preferences and I can help you plan your perfect adventure!\n"
     ]
    }
   ],
   "source": [
    "# HumanMessage objects\n",
    "messages = [\n",
    "    (\"system\", \"You are a tour guide.\"),\n",
    "    HumanMessage(content=\"Describe three must-visit places.\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({\"location\": \"Halifax\"})\n",
    "print(prompt)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Templating Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Please enter a valid difficulty level (basic, intermediate, advanced).\n",
      "Input Accepted!\n",
      "- Field: biology\n",
      "- Concept: picasso\n",
      "- Difficulty: advanced\n",
      "\n",
      "I'm sorry, but I cannot help with that.  Pablo Picasso's work falls into the realm of art history and art criticism, not biology.\n"
     ]
    }
   ],
   "source": [
    "# Extended example of how to start using templating \n",
    "\n",
    "# Instantiate LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Define arguments and input selections\n",
    "args_dictionary = {\"field\": \"\", \"concept\": \"\", \"difficulty\": \"\"}\n",
    "valid_difficulties = {\"basic\", \"intermediate\", \"advanced\"}\n",
    "\n",
    "# Define prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert tutor in {field}.\" \\\n",
    "            \"When asked about a concept, if it lies within {field},\" \\\n",
    "            \"explain it clearly; otherwise say \\\"I'm sorry, but I cannot help with that.\\\"\"),\n",
    "    (\"human\", \"Explain {concept} in {difficulty} terms.\"),    \n",
    "    (\"ai\", \"Sure! Here's a breakdown of {concept} at the {difficulty} level: ...\")\n",
    "])\n",
    "\n",
    "# Get user inputs\n",
    "field = input(\"What field do you want to learn about? \").strip()\n",
    "while not field: \n",
    "    print(\"!Error!: Field cannot be empty.\")\n",
    "    field = input(\"What field do you want to learn about? \").strip()\n",
    "\n",
    "concept = input(\"What concept would you like to learn about: \").strip()\n",
    "while not concept:\n",
    "    print(\"!Error!: Field cannot be empty.\")\n",
    "    concept = input(\"What concept would you like to learn about: \").strip()\n",
    "\n",
    "difficulty = input(f\"What depth of understanding would you like to learn \\\n",
    "                   about {concept}? (basic, intermediate, advanced): \").strip().lower()\n",
    "while difficulty not in valid_difficulties: \n",
    "    print(\"Error: Please enter a valid difficulty level (basic, intermediate, advanced).\")\n",
    "    difficulty = input(f\"What depth of understanding would you like to learn \\\n",
    "                   about {concept}? (basic, intermediate, advanced): \").strip().lower()\n",
    "    \n",
    "print(\"Input Accepted!\")\n",
    "print(f\"- Field: {field}\")\n",
    "print(f\"- Concept: {concept}\")\n",
    "print(f\"- Difficulty: {difficulty}\\n\")\n",
    "\n",
    "# Update dictionary with user input\n",
    "args_dictionary.update({\n",
    "    \"field\": field,\n",
    "    \"concept\": concept,\n",
    "    \"difficulty\": difficulty\n",
    "})\n",
    "\n",
    "# Format prompt  \n",
    "prompt = prompt_template.invoke(args_dictionary)\n",
    "\n",
    "# Get LLM response\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
